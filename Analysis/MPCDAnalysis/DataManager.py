from .Configuration import Configuration
from .Run import Run

import copy
import glob
import os.path
import pylibconfig2
import yaml

class DataManager:
	"""
	Provides information on the data that have been generated by OpenMPCD.

	Throughout this class, the a "config part generator" is understood to be a
	generator in the Python sense (c.f. the `yield` keyword), which yields a
	list; each of the elements of this list is a dictionary, containing:
	  - `settings`:
	    A dictionary, with each key being a configuration setting name, and the
	    value being the corresponding value;
	  - `pathComponents`:
	    A list of all path components that the generator request be added to the
	    run directory name.
	  - `targetSweepCount`:
	    The minimum number of sweeps this configuration must be simulated for,
	    possibly across multiple runs. Set to `None` if no such minimum is
	    desired.
	"""

	@staticmethod
	def getConfigurationPath():
		"""
		Returns the path at which the configuration file for this class is
		expected.
		"""

		return os.path.expanduser("~/.OpenMPCD/config/DataManager.yaml")


	def __init__(self, dataPaths = None):
		"""
		The constructor.

		This will require the file returned by `getConfigurationPath`
		to be readable, and contain in `dataPaths` a list of OpenMPCD run
		directories. Each entry in the list will be processed through Python's
		`glob.glob` function, and as such, special tokens such as '*' may be
		used to match a larger number of directories. If any of the matching
		directories is found to not be a OpenMPCD run directory, it is ignored.
		Furthermore, each entry in `dataPaths` may contain an initial '~'
		character, which will be expanded to the user's home directory.

		Alternatively, the list of data paths may be supplied as the `dataPaths`
		variable, which takes over the configuration file.

		@param[in] dataPaths
		           A list of data paths, or `None` for the default (see function
		           description).
		"""

		if dataPaths is not None:
			if not isinstance(dataPaths, list):
				raise TypeError()


		configPath = self.getConfigurationPath()

		config = yaml.safe_load(open(configPath, "r"))

		if dataPaths is None:
			dataPathsPreGlob = config["dataPaths"]
		else:
			dataPathsPreGlob = dataPaths

		dataPathsPreGlob = [os.path.expanduser(x) for x in dataPathsPreGlob]
		dataPaths = []
		for path in dataPathsPreGlob:
			dataPaths += glob.glob(path)

		self.rundirs = []
		for path in dataPaths:
			self.rundirs.append(path)

		self.runs = None

		self.pathTranslators = []
		if "pathTranslators" in config:
			for translator in config["pathTranslators"]:
				self.pathTranslators.append(translator)

		self.pathTranslatorsServerToLocal = []
		for translator in self.pathTranslators:
			self.pathTranslatorsServerToLocal.append(
				lambda x: x.replace(translator["server"], translator["local"]))

		self.projects = config["projects"] if "projects" in config else []
		self.project = None

		self.cluster = None
		if "cluster" in config:
			self.cluster = config["cluster"]

			originalNodeList = copy.deepcopy(self.cluster["nodes"])
			self.cluster["nodes"] = []

			for nodeSpecification in originalNodeList:
				nodeNames = self._parseSlrumNodeList(nodeSpecification["name"])
				for name in nodeNames:
					newNode = copy.deepcopy(nodeSpecification)
					newNode["name"] = name
					self.cluster["nodes"].append(newNode)


	def getProjects(self):
		"""
		Returns all configured projects.
		"""

		return self.projects


	def getClusterNodesGroupedByGPUCount(self):
		"""
		Returns a dictionary, with each key corresponding the number of GPUs
		installed on the individual systems grouped in the corresponding
		dictionary value. Each value is a dictionary, with the following
		entries:
			* "nodes": A list of nodes that fall into that category
			* "SlurmNodeList": A string, compatible with the `Slurm` scheduler,
			  that collects all the nodes in entry `nodes`.
		"""

		ret = {}

		if self.cluster is None:
			return ret

		for node in self.cluster["nodes"]:
			GPUCount = node["GPUCount"]
			if GPUCount not in ret:
				ret[GPUCount] = {"nodes": []}
			ret[GPUCount]["nodes"].append(node["name"])

		for key in ret:
			ret[key]["SlurmNodeList"] = \
				self._makeSlurmNodeList(ret[key]["nodes"])

		return ret


	def getSubmittedJobBatchesGroupedByJobBatchSize(self):
		"""
		Returns a dictionary, with each key being a number of jobs executed in
		parallel on one node, and the value being the list of job batches
		having exactly this many jobs, which are submitted and pending
		execution.
		"""

		ret = {}

		for run in self.getRuns():
			if run.hasParentRun():
				continue

			if run.getState() != Run.RunState.Submitted:
				continue

			batchSize = run.getJobBatchSize()
			if batchSize not in ret:
				ret[batchSize] = []

			ret[batchSize].append(run)

		return ret


	def selectProject(self, name):
		"""
		Selects the project of the given `name` as the currently active one.
		"""

		for project in self.projects:
			if project["name"] == name:
				self.project = project

				jobDirectoryBasePathOnLocalMachine = \
					project["jobDirectoryBasePathOnLocalMachine"]
				jobDirectoryBasePathOnServer = \
					project["jobDirectoryBasePathOnServer"]

				def pathTranslator(
					path,
					localroot = jobDirectoryBasePathOnLocalMachine,
					serverroot = jobDirectoryBasePathOnServer):
						if path.startswith(localroot):
							path = path.replace(localroot, serverroot, 1)
						return path

				execfileScope = {
					"jobDirectoryBasePathOnLocalMachine":
						jobDirectoryBasePathOnLocalMachine,
					"jobDirectoryBasePathOnServer":
						jobDirectoryBasePathOnServer,
					"pathTranslator": pathTranslator,
					"Configuration": Configuration}
				self._execfile(
					project["targetDataSpecificationFilePath"], execfileScope)
				self.project["baseConfig"] = execfileScope['baseConfig']
				self.project["configPartGenerators"] = \
					execfileScope['generators']
				return

		raise Exception("Unknown project: " + name)


	def getProject(self):
		"""
		Returns the currently selected project, or `None` if none has been
		selected.
		"""

		return self.project


	def getRuns(self):
		"""
		Returns a list of `Run` instances, corresponding to the run directories
		that have been found.
		"""

		if self.runs is None:
			self.runs = [
				Run(rundir, self.pathTranslatorsServerToLocal)
				for rundir in self.rundirs
				]

		return self.runs


	def getNumberOfSweepsByRun(self, run):
		"""
		Returns the number of completed sweeps in the given `run`, which may be
		an instance of `Run`, or be a string pointing to a run directory.
		The returned value corresponds to `run.getNumberOfCompletedSweeps()`,
		pretending that `run` is indeed an instance of `Run`.
		"""

		if not isinstance(run, Run):
			run = Run(run)

		return run.getNumberOfCompletedSweeps()


	def getNumberOfSweepsByRuns(self, rundirs):
		"""
		Returns the sum of the number of completed sweeps in all of the given
		`runs`, which may be instances of `Run`, or strings pointing to run
		directories.
		"""

		ret = 0
		for rundir in rundirs:
			ret += self.getNumberOfSweepsByRun(rundir)

		return ret


	def getRunsFilteredByConfig(self, filters):
		"""
		Returns a list of runs that match the given criteria.

		The argument `filters` is expected to be a function, or a list of
		functions, each taking an object that represents the configuration for a
		particular run, returning `False` if it should be filtered out of the
		result set, or `True` otherwise (filters applied later might still
		remove that configuration from the result set).
		"""

		if not isinstance(filters, list):
			filters = [filters]

		ret = []

		for run in self.getRuns():
			config = run.getConfiguration()

			exclude = False
			for filter_ in filters:
				if not filter_(config):
					exclude = True
					break

			if not exclude:
				ret.append(run)

		return ret


	def getRunsWithMatchingConfiguration(
			self, configuration, pathTranslators = []):
		"""
		Returns the result of `getRuns` filtered by the condition that the run's
		configuration must be equivalent (in the sense of
		`Configuration.isEquivalent`) to the given `configuration`.

		@param[in] pathTranslators
		           This argument will be passed as the `pathTranslators`
		           argument to `Configuration.isEquivalent`.
		"""

		runs = self.getRuns()
		ret = []

		for run in runs:
			equivalent = \
				run.getConfiguration().isEquivalent(
					configuration, pathTranslators = pathTranslators)
			if equivalent:
				ret.append(run)

		return ret


	def getTargetDataSpecifications(self):
		"""
		Returns, for the currently selected project, a list of dictionaries;
		the latter each contain a key `config`, which contains a `Configuration`
		instance, and a key `targetSweepCount`, which contains the number of
		sweeps that are desired to be in the data gathered with this
		configuration, or `None` if none is specified. Furthermore, the key
		`pathComponents` contains a list of all path components that the
		generators request be added to the run directory name.
		"""

		if self.project is None:
			raise Exception()

		ret = []

		import itertools

		for generators in self.project["configPartGenerators"]:
			for element in itertools.product(*generators):
				config = copy.deepcopy(self.project["baseConfig"])
				pathComponents = []
				targetSweepCount = None
				for configPart in element:
					for name, value in configPart["settings"].items():
						if isinstance(value, ConfigPartSpecialAction):
							if value.isDelete():
								del config[name]
							elif value.isCreateGroup():
								config.createGroup(name)
							else:
								raise RuntimeError("Unknown action.")
						else:
							config[name] = value

					if configPart["pathComponents"] is not None:
						pathComponents += configPart["pathComponents"]

					if configPart["targetSweepCount"] is not None:
						tmp = configPart["targetSweepCount"]
						if targetSweepCount is None or tmp > targetSweepCount:
							targetSweepCount = tmp

				ret.append({
					"config": config,
					"targetSweepCount": targetSweepCount,
					"pathComponents": pathComponents})

		return ret


	def getTargetDataSpecificationStatus(
			self, specification, defaultTargetSweepCount = None):
		"""
		For the given target data `specification`, returns:
		  - `"completed"`
		    if the specification has achieved its target sweep count,
		  - `"pending"`
		    if it is not yet completed, but has runs being executed or being
		    scheduled for execution, or
		  - `"incomplete"` in any other case.

		@param[in] defaultTargetSweepCount
		           This parameter is used as the sweep count for target data
		           specifications that do not have a target sweep count set.
		           If `defaultTargetSweepCount` parameter is `None`, all target
		           data specifications must specify a target sweep count.
		"""

		runs = \
			self.getRunsWithMatchingConfiguration(
				specification["config"], self.pathTranslatorsServerToLocal)
		sweepCount = self.getNumberOfSweepsByRuns(runs)
		targetSweepCount = specification["targetSweepCount"]
		if targetSweepCount is None:
			if defaultTargetSweepCount is None:
				raise Exception()
			targetSweepCount = defaultTargetSweepCount

		if sweepCount >= targetSweepCount:
			return "completed"

		isPending = False
		pendingStates = [Run.RunState.Running, Run.RunState.Submitted]
		for run in runs:
			if run.getState() in pendingStates:
				isPending = True
				break

		if isPending:
			return "pending"

		return "incomplete"


	def getTargetDataSpecificationsGroupedByStatus(
			self, defaultTargetSweepCount = None):
		"""
		Takes the values returned by `getTargetDataSpecifications`, and groups
		them into three categories in the returned dictionary: `completed`
		contains all the target data specifications that have achieved their
		target sweep counts, `pending` contains all the target data
		specifications that are not yet completed, but have runs being executed
		or being scheduled for execution, and `incomplete` contains the rest.

		@param[in] defaultTargetSweepCount
		           This parameter is used as the sweep count for target data
		           specifications that do not have a target sweep count set.
		           If `defaultTargetSweepCount` parameter is `None`, all target
		           data specifications must specify a target sweep count.
		"""

		ret = {
			"completed": [],
			"pending": [],
			"incomplete": []
			}

		specifications = self.getTargetDataSpecifications()
		for specification in specifications:
			status = \
				self.getTargetDataSpecificationStatus(
					specification, defaultTargetSweepCount)

			ret[status].append(specification)

		return ret


	def createRundirByTargetDataSpecification(self, specification):
		"""
		Creates a new rundir, and configuration files therein, for the given
		target data specification (c.f. `getTargetDataSpecifications`), and
		returns the newly created path.
		"""

		if self.project is None:
			raise Exception("You need to select a project.")

		basePath = self.project["jobDirectoryBasePathOnLocalMachine"] + "/jobs"

		if not os.path.isdir(basePath):
			raise ValueError("Base path does not exist: " + basePath)

		config = specification["config"]

		pathComponents = None
		if "rundirNamePrefix" in self.project:
			pathComponents = self.project["rundirNamePrefix"]

		for pathComponent in specification["pathComponents"]:
				if pathComponents:
					pathComponents += "---"
				pathComponents += pathComponent

		numberOfDigits = 4
		for x in range(0, pow(10, numberOfDigits)):
			path = \
				basePath + "/" + \
				pathComponents + "---" + \
				("{:0>" + str(numberOfDigits) + "}").format(x)

			if not os.path.exists(path):
				os.mkdir(path)
				with open(path + "/config.txt", "w") as f:
					f.write(str(config))
				return path


	def createSlurmJobScripts(
		self, rundirs, executablePath, executableOptions,
		slurmOptions = {}, srunOptions = {},
		chunkSize = 1, excludedNodes = None,
		pathTranslator = None):
		"""
		For each of the given `rundirs`, creates a Slurm job script at
		`input/job.slrm` (relative to the respective rundir) that can be used to
		submit a job via `sbatch`, or alternatively, if the rundir is part of a
		larger job controlled via a jobscript in another run directory, creates
		the file `input/parent-job-path.txt`, which contains the absolute path
		to the parent job.

		The job script will assume that the OpenMPCD executable will reside at
		`executablePath`, which should most probably be an absolute path. The
		`--rundir` option, with the respective rundir specification as its
		value, will be added to the string of program arguments
		`executableOptions`.

		`executableOptions` is a string that contains all options that are
		passed to the executable upon invocation, as if specified in `bash`.

		`slurmOptions` is a dictionary, with each key specifying a Slurm
		`sbatch` option (e.g. "-J" or "--job-name") and its value specifying
		that option's value. There, the special string "$JOBS_PER_NODE" will be
		replaced with the number of individual invocations of the given
		executable in the current Slurm job. See `chunkSize` below.
		Furthermore, for each value, the special string "$RUNDIR" will be
		replaced with the absolute path to the run directory that will contain
		the `sbatch` job script.

		`srunOptions` is a dictionary, with each key specifying a `srun` option
		(e.g. --gres") and its value specifying that option's value, or `None`
		if there is no value.
		For each value, the special string "$RUNDIR" will be replaced with the
		absolute path to the run directory.

		`chunkSize` can be used to specify that one Slurm job should contain
		`chunkSize` many individual invocations of the executable given. If
		the number of `rundirs` is not divisible `chunkSize`, an exception is
		thrown.

		If `excludedNodes` is not `None`, it is a string describing,
		in Slurm's syntax (e.g. "n25-02[1-2]"), which compude nodes
		should be excluded from executing the jobs.

		If `pathTranslator` is not `None`, it is called on each absolute path
		before writing its value to some file, or returning it from this
		function.
		This is useful if this program is run on one computer, but the resulting
		files will be on another, where the root directory of the project (or
		the user's home) is different.

		The function returns a list of server paths to the created jobfiles.
		"""

		if len(rundirs) % chunkSize != 0:
			raise Exception()

		if excludedNodes is not None:
			for x in ["-w", "--nodelist", "-x", "--exclude"]:
				if x in slurmOptions:
					raise ValueError(
						"Cannot have Slurm option " + x + " if " + \
						"`nodeSpecification` is given")

		for x in ["-D", "--chdir"]:
			if x in srunOptions:
				raise ValueError("Cannot have option " + x + " in srunOptions")

		if not pathTranslator:
			pathTranslator = lambda x: x

		jobfiles = []

		chunks = \
			[
				rundirs[first:first + chunkSize]
				for first in range(0, len(rundirs), chunkSize)
			]


		for chunk in chunks:
			script = "#!/bin/bash" + "\n"

			jobsInChunk = len(chunk)
			jobfileRundirPath = os.path.abspath(chunk[0])
			jobfilePath = jobfileRundirPath + "/input/job.slrm"
			mySlurmOptions = slurmOptions.copy()

			if not os.path.isdir(jobfileRundirPath + "/input"):
				os.mkdir(jobfileRundirPath + "/input")

			if excludedNodes is not None:
				mySlurmOptions["--exclude"] = excludedNodes

			for key, value in mySlurmOptions.items():
				script += "#SBATCH " + key
				if key[1] == "-":
					script += "="
				else:
					script += " "

				value = \
					value.replace("$RUNDIR", pathTranslator(jobfileRundirPath))
				value = value.replace("$JOBS_PER_NODE", str(jobsInChunk))
				script += value
				script += "\n"

			script += "\n"

			for rundir in chunk:
				if not os.path.isdir(rundir + "/input"):
					os.mkdir(rundir + "/input")

				if rundir != jobfileRundirPath:
					parentJobPath = rundir + "/input/parent-job-path.txt"
					with open(parentJobPath, "w") as f:
						f.write(pathTranslator(jobfileRundirPath))

				absolutePath = pathTranslator(os.path.abspath(rundir))

				script += "srun"
				script += " --chdir='" + absolutePath + "/input'"

				for key, value in srunOptions.items():
					script += " " + key
					if value is not None:
						if key[1] == "-":
							script += "="
						else:
							script += " "
						script += value.replace("$RUNDIR", absolutePath)

				script += " '" + executablePath + "'"
				script += " " + executableOptions
				script += " --rundir '" + absolutePath + "'"
				script += " & \n"

			script += "wait" + "\n"

			with open(jobfilePath, "w") as jobfile:
				jobfile.write(script)


			jobfiles.append(pathTranslator(jobfilePath))

		return jobfiles


	def __deprecated__createRundirs(
			self, baseConfig, basePath, generators, rundirNamePrefix = ""):
		"""
		Creates new rundirs, and configuration files therein.

		The `generators` argument is supposed to be either a config part,
		generator,or a list of such functions.
		One rundir and configuration will be created per element of the
		Cartesian product of all the config part generators. The configurations
		will be based on the `baseConfig` template, and the rundirs will be
		created as child directories of `basePath`.

		`rundirNamePrefix` is a prefix that is prepended to all rundir directory
		names.

		The function returns a list of all created run directories.
		"""

		if not isinstance(generators, list):
			generators = [generators]

		if not os.path.isdir(basePath):
			raise ValueError("Base path does not exist: " + basePath)

		ret = []

		import itertools

		for instance in itertools.product(*generators):
			config = copy.deepcopy(baseConfig)
			pathComponents = rundirNamePrefix
			for setting in instance:
				name, value, pathComponent = setting

				config[name] = value

				if pathComponent is not None:
					pathComponents += "---" + pathComponent

			numberOfDigits = 4
			for x in range(0, pow(10, numberOfDigits)):
				path = \
					basePath + "/" + \
					pathComponents + "---" + \
					("{:0>" + str(numberOfDigits) + "}").format(x)
				if not os.path.exists(path):
					os.mkdir(path)
					ret.append(path)
					with open(path + "/config.txt", "w") as f:
						f.write(str(config))
					break

		return ret



	def __deprecated__createSlurmJobScripts(
		self, rundirs, executablePath, executableOptions,
		slurmOptions = {}, srunOptions = {},
		chunkSize = 1, largeChunkNodeSpecification = None,
		pathTranslator = None):
		"""
		For each of the given `rundirs`, creates a Slurm job script at
		`input/job.slrm` (relative to the respective rundir) that can be used to
		submit a job via `sbatch`, or alternatively, if the rundir is part of a
		larger job controlled via a jobscript in another run directory, creates
		the file `input/parent-job-path.txt`, which contains the absolute path
		to the parent job.

		The job script will assume that the OpenMPCD executable will reside at
		`executablePath`, which should most probably be an absolute path. The
		`--rundir` option will be added to that list with the respective rundir
		specification.

		`executableOptions` is a string that contains all options that are
		passed to the executable upon invocation, as if specified in `bash`.

		`slurmOptions` is a dictionary, with each key specifying a Slurm
		`sbatch` option (e.g. "-J" or "--job-name") and its value specifying
		that option's value. There, the special string "$JOBS_PER_NODE" will be
		replaced with the number of individual invocations of the given
		executable in the current Slurm job. See `chunkSize` below.
		Furthermore, for each value, the special string "$RUNDIR" will be
		replaced with the absolute path to the run directory that will contain
		the `sbatch` job script.

		`srunOptions` is a dictionary, with each key specifying a `srun` option
		(e.g. --gres") and its value specifying that option's value, or `None`
		if there is no value.
		For each value, the special string "$RUNDIR" will be replaced with the
		absolute path to the run directory.

		`chunkSize` can be used to specify that one Slurm job should contain
		`chunkSize` many individual invocations of the executable given. If
		the number of `rundirs` is not divisible `chunkSize`, as many chunks of
		size `chunkSize` are produced, and the remainder of the given `rundirs`
		are put into chunks of size `1`.
		This is useful if one has compute nodes with multiple GPUs than can run
		more than one job in parallel, and the scheduler is not configured to
		allow multiple jobs to share a node.

		If `largeChunkNodeSpecification` is not `None`, it is a string
		describing, in Slurm's syntax (e.g. "n25-02[1-2]"), which compude nodes
		should be excluded from executing jobs that have been grouped into
		chunks less than `chunkSize`. Also, these nodes are excluded if
		`chunkSize == 1`.

		If `pathTranslator` is not `None`, it is called on each absolute path
		before writing its value to some file, or returning it from this
		function.
		This is useful if this program is run on one computer, but the resulting
		files will be on another, where the root directory of the project (or
		the user's home) is different.

		The function returns a list of paths to the created jobfiles.
		"""

		if largeChunkNodeSpecification is not None and chunkSize != 1:
			for x in ["-w", "--nodelist", "-x", "--exclude"]:
				if x in slurmOptions:
					raise ValueError(
						"Cannot have Slurm option " + x + " if " + \
						"`chunkSize != 1` and " + \
						"`largeChunkNodeSpecification` is given")

		for x in ["-D", "--chdir"]:
			if x in srunOptions:
				raise ValueError("Cannot have option " + x + " in srunOptions")

		if not pathTranslator:
			pathTranslator = lambda x: x

		jobfiles = []

		chunks = \
			[
				rundirs[first:first + chunkSize]
				for first in range(0, len(rundirs), chunkSize)
			]

		if len(chunks[-1]) < chunkSize:
			popped = chunks.pop()
			for x in popped:
				chunks.append([x])

		for chunk in chunks:
			script = "#!/bin/bash" + "\n"

			jobsInChunk = len(chunk)
			jobfileRundirPath = os.path.abspath(chunk[0])
			jobfilePath = jobfileRundirPath + "/input/job.slrm"
			mySlurmOptions = slurmOptions.copy()

			if not os.path.isdir(jobfileRundirPath + "/input"):
				os.mkdir(jobfileRundirPath + "/input")

			if largeChunkNodeSpecification is not None:
				if jobsInChunk < chunkSize or chunkSize == 1:
					mySlurmOptions["--exclude"] = largeChunkNodeSpecification

			for key, value in mySlurmOptions.items():
				script += "#SBATCH " + key
				if key[1] == "-":
					script += "="
				else:
					script += " "

				value = \
					value.replace("$RUNDIR", pathTranslator(jobfileRundirPath))
				value = value.replace("$JOBS_PER_NODE", str(jobsInChunk))
				script += value
				script += "\n"

			script += "\n"

			for rundir in chunk:
				if not os.path.isdir(rundir + "/input"):
					os.mkdir(rundir + "/input")

				if rundir != jobfileRundirPath:
					parentJobPath = rundir + "/input/parent-job-path.txt"
					with open(parentJobPath, "w") as f:
						f.write(pathTranslator(jobfileRundirPath))

				absolutePath = pathTranslator(os.path.abspath(rundir))

				script += "srun"
				script += " --chdir='" + absolutePath + "/input'"

				for key, value in srunOptions.items():
					script += " " + key
					if value is not None:
						if key[1] == "-":
							script += "="
						else:
							script += " "
						script += value.replace("$RUNDIR", absolutePath)

				script += " '" + executablePath + "'"
				script += " " + executableOptions
				script += " --rundir '" + absolutePath + "'"
				script += " & \n"

			script += "wait" + "\n"

			with open(jobfilePath, "w") as jobfile:
				jobfile.write(script)


			jobfiles.append(pathTranslator(jobfilePath))

		return jobfiles


	def _makeSlurmNodeList(self, nodes):
		"""
		Returns a `Slurm`-compatible node-specification string.
		"""

		ret = ""
		for node in nodes:
			if ret:
				ret += ","
			ret += node

		return ret


	def _parseSlrumNodeList(self, nodeList):
		"""
		Returns a list of node names, corresponding to the `Slurm` node list.
		"""

		ret = []

		if "," in nodeList:
			parts = nodeList.split(",")
			for part in parts:
				ret += self._parseSlrumNodeList(part)
			return ret

		import re

		regex = r"\[([0-9]+)-([0-9]+)\]"
		parts = re.split(regex, nodeList)
		if len(parts) > 1:
			prefix = parts[0]
			suffix = parts[3]
			start = int(parts[1])
			end = int(parts[2])
			for number in range(start, end + 1):
				ret += self._parseSlrumNodeList(prefix + str(number) + suffix)
			return ret

		return [nodeList]

	def _execfile(self, path, myGlobals = None, myLocals = None):
		"""
		Executes the file's contents in the current context.
		"""

		with open(path) as f:
			exec(compile(f.read(), path, 'exec'), myGlobals, myLocals)


class ConfigPartSpecialAction:
	"""
	Class that represents a special action to be performed in config part
	generators, like deleting settings or creating setting groups.
	"""

	def __init__(self, action):
		"""
		The constructor.

		@throw TypeError
		       Throws if `action` is not a `str`.
		@throw ValueError
		       Throws if `action` has an illegal value.

		@param[in] action
		           The action to perform on the associated setting. Can be
		           `"delete"` to delete the setting (and possibly any
		           sub-settings), or `"createGroup"` to create a settings
		           group of that name.
		"""

		if not isinstance(action, str):
			raise TypeError()

		if action not in ["delete", "createGroup"]:
			raise ValueError(action)

		self._action = action


	def isDelete(self):
		"""
		Returns whether the action is to delete the associated setting.
		"""

		return self._action == "delete"


	def isCreateGroup(self):
		"""
		Returns whether the action is to create the associated setting group.
		"""

		return self._action == "createGroup"
